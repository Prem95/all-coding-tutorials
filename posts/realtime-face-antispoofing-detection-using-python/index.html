<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.08b6f1b92a40a3f4c705.css" id="gatsby-global-css">html{font-size:100}body{margin:0 0 0 calc(100vw - 100%);color:#222;line-height:1.625;font-size:1rem;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}body,h1,h2,h3,h4,h5,h6{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1,h2,h3,h4,h5,h6{font-weight:600}h1{font-size:2.5rem;line-height:3.25rem;margin-top:6.5rem;margin-bottom:1.625rem}h2{font-size:1.6875rem;line-height:2.4375rem}h2,h3{margin-top:3.25rem;margin-bottom:.8125rem}h3{font-size:1.375rem;line-height:1.625rem}h4{font-size:1.2rem;margin-top:2.4375rem}h4,h5{line-height:1.625rem;margin-bottom:.8125rem}h5,h6{font-size:1rem;margin-top:4.0625rem}h6{line-height:1.625rem;margin-bottom:.8125rem}img{max-width:100%;margin:inherit auto}hr,img{border:0;display:block}hr{color:#222;height:1.625rem;margin:3.25rem auto;background-size:100% 26px;background-image:linear-gradient(180deg,transparent 1px,transparent 11px,#222 0,#222 15px,transparent 0,transparent 26px);width:6.25rem}a{color:#5d93ff;text-decoration:none}a:active,a:focus,a:hover{color:#f7a046}b,strong{font-weight:600}ul{list-style:square;margin-bottom:1.625rem}ul li{padding:0 .3125rem;margin-bottom:.625rem}p{line-height:1.625rem;margin-bottom:1.625rem}blockquote{padding:0;font-style:italic;text-align:center}figure{display:block;width:100%;height:auto}figcaption{line-height:1.21875rem;margin-top:.40625rem;color:#222;font-size:.875rem;font-style:italic;margin-bottom:0;text-align:center}.anchor{margin-left:-1.875rem!important;padding-right:.875rem!important}@media screen and (min-width:685px){figure.float-left,figure.float-right{max-width:19.375rem;padding:0 1.625rem}.float-right{float:right}.float-left{float:left}}code[class*=language-],pre[class*=language-]{color:#657b83;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-]::selection,code[class*=language-] ::selection,pre[class*=language-]::selection,pre[class*=language-] ::selection{background:#073642}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background-color:#fdf6e3}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#93a1a1}.token.punctuation{color:#586e75}.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#268bd2}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string,.token.url{color:#2aa198}.token.entity{color:#657b83;background:#eee8d5}.token.atrule,.token.attr-value,.token.keyword{color:#859900}.token.class-name,.token.function{color:#b58900}.token.important,.token.regex,.token.variable{color:#cb4b16}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.Author-module--author__photo--36xCH{display:inline-block;margin-bottom:0;border-radius:50%;background-clip:padding-box}.Author-module--author__title--2CaTb{font-size:1.125rem;font-weight:600;line-height:1.82813rem;margin:.8125rem 0}.Author-module--author__title-link--Yrism,.Author-module--author__title-link--Yrism:focus,.Author-module--author__title-link--Yrism:hover{color:#222}.Author-module--author__subtitle--cAaEB{color:#888;line-height:1.625rem;margin-bottom:1.625rem}.Icon-module--icon--Gpyvw{display:inline-block;width:1em;height:1em;stroke-width:0;stroke:currentColor;fill:currentColor;font-style:normal;font-weight:400;speak:none;margin-right:.2em;text-align:center;font-variant:normal;text-transform:none;line-height:1em;margin-left:.2em;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.Contacts-module--contacts--1rGd1{margin-bottom:1.625rem}.Contacts-module--contacts__list--3OgdW{display:flex;flex-flow:row wrap;flex-grow:0;flex-shrink:0;list-style:none;padding:0;margin:.625rem -.1875rem;width:8.75rem}.Contacts-module--contacts__list-item--16p9q{padding:0;margin:.25rem;display:flex;align-content:center;align-items:center;justify-content:center;height:2.1875rem;width:2.1875rem;line-height:2.1875rem;border-radius:50%;text-align:center;border:1px solid #ebebeb}.Contacts-module--contacts__list-item-link--2MIDn{border:0;display:flex;color:#222}.Contacts-module--contacts__list-item-link--2MIDn:focus,.Contacts-module--contacts__list-item-link--2MIDn:hover{color:#5d93ff}.Copyright-module--copyright--1ariN{color:#b6b6b6;font-size:.875rem}.Menu-module--menu--Efbin{margin-bottom:1.625rem}.Menu-module--menu__list--31Zeo{list-style:none;padding:0;margin:0}.Menu-module--menu__list-item--1lJ6B{padding:0;margin:.625rem 0}.Menu-module--menu__list-item-link--10Ush{font-size:1rem;color:#222;font-weight:400;border:0}.Menu-module--menu__list-item-link--10Ush:focus,.Menu-module--menu__list-item-link--10Ush:hover{color:#5d93ff;border-bottom:1px solid #5d93ff}.Menu-module--menu__list-item-link--active--2CbUO{color:#222;border-bottom:1px solid #222}.Sidebar-module--sidebar--X4z2p{width:100%}.Sidebar-module--sidebar__inner--Jdc5s{position:relative;padding:1.5625rem 1.25rem 0}@media screen and (min-width:685px){.Sidebar-module--sidebar--X4z2p{width:calc(41.625% - 1.09375rem)}.Sidebar-module--sidebar--X4z2p:nth-child(1n){float:left;margin-right:1.875rem;clear:none}.Sidebar-module--sidebar--X4z2p:last-child{margin-right:0}.Sidebar-module--sidebar--X4z2p:nth-child(12n){margin-right:0;float:right}.Sidebar-module--sidebar--X4z2p:nth-child(12n+1){clear:both}.Sidebar-module--sidebar__inner--Jdc5s{padding:1.875rem 1.25rem 0}.Sidebar-module--sidebar__inner--Jdc5s:after{background:#e6e6e6;background:linear-gradient(180deg,#e6e6e6 0,#e6e6e6 48%,#fff);position:absolute;content:"";width:.0625rem;height:33.75rem;top:30px;right:-10px;bottom:0}}@media screen and (min-width:960px){.Sidebar-module--sidebar--X4z2p{width:calc(33.3% - 1.25rem)}.Sidebar-module--sidebar--X4z2p:nth-child(1n){float:left;margin-right:1.875rem;clear:none}.Sidebar-module--sidebar--X4z2p:last-child{margin-right:0}.Sidebar-module--sidebar--X4z2p:nth-child(3n){margin-right:0;float:right}.Sidebar-module--sidebar--X4z2p:nth-child(3n+1){clear:both}.Sidebar-module--sidebar__inner--Jdc5s{padding:2.5rem}}.Layout-module--layout--3Pyz6{max-width:66.875rem;margin-left:auto;margin-right:auto}.Layout-module--layout--3Pyz6:before{content:"";display:table}.Layout-module--layout--3Pyz6:after{content:"";display:table;clear:both}.Feed-module--feed__item--2D5rE{margin-bottom:2.03125rem}.Feed-module--feed__item--2D5rE:last-child{margin-bottom:.8125rem}.Feed-module--feed__item-title--3nigr{font-size:1.6875rem;line-height:2.4375rem;margin-top:0;margin-bottom:.8125rem}.Feed-module--feed__item-title-link--iFMRs{color:#222}.Feed-module--feed__item-title-link--iFMRs:focus,.Feed-module--feed__item-title-link--iFMRs:hover{color:#222;border-bottom:1px solid #222}.Feed-module--feed__item-description--1uO8e{font-size:1rem;line-height:1.625rem;margin-bottom:1.21875rem}.Feed-module--feed__item-meta-time--3t1fg{font-size:.875rem;color:#222;font-weight:600;text-transform:uppercase}.Feed-module--feed__item-meta-divider--N-Q0A{margin:0 .3125rem}.Feed-module--feed__item-meta-category-link--23f8F{font-size:.875rem;color:#f7a046;font-weight:600;text-transform:uppercase}.Feed-module--feed__item-meta-category-link--23f8F:focus,.Feed-module--feed__item-meta-category-link--23f8F:hover{color:#5d93ff}.Feed-module--feed__item-readmore--1u6bI{font-size:1rem;color:#5d93ff}.Feed-module--feed__item-readmore--1u6bI:focus,.Feed-module--feed__item-readmore--1u6bI:hover{color:#5d93ff;border-bottom:1px solid #5d93ff}.Page-module--page--2nMky{margin-bottom:3.25rem}.Page-module--page__inner--2M_vz{padding:1.5625rem 1.25rem}.Page-module--page__title--GPD8L{font-size:2.5rem;font-weight:600;line-height:3.25rem;margin-top:0;margin-bottom:2.35625rem}.Page-module--page__body--Ic6i6{font-size:1rem;line-height:1.625rem;margin:0 0 1.625rem}@media screen and (min-width:685px){.Page-module--page--2nMky{width:calc(58.275% - .78125rem)}.Page-module--page--2nMky:nth-child(1n){float:left;margin-right:1.875rem;clear:none}.Page-module--page--2nMky:last-child{margin-right:0}.Page-module--page--2nMky:nth-child(12n){margin-right:0;float:right}.Page-module--page--2nMky:nth-child(12n+1){clear:both}.Page-module--page__inner--2M_vz{padding:1.875rem 1.25rem}}@media screen and (min-width:960px){.Page-module--page--2nMky{width:calc(66.6% - .625rem)}.Page-module--page--2nMky:nth-child(1n){float:left;margin-right:1.875rem;clear:none}.Page-module--page--2nMky:last-child{margin-right:0}.Page-module--page--2nMky:nth-child(3n){margin-right:0;float:right}.Page-module--page--2nMky:nth-child(3n+1){clear:both}.Page-module--page__inner--2M_vz{padding:2.5rem 2.1875rem}}.Pagination-module--pagination--2H3nO{margin-top:3.25rem;display:flex}.Pagination-module--pagination__prev--bet5s{width:50%;text-align:left}.Pagination-module--pagination__prev-link--1Nzs6{color:#f7a046;font-size:1.625rem;font-weight:700}.Pagination-module--pagination__prev-link--1Nzs6:focus,.Pagination-module--pagination__prev-link--1Nzs6:hover{color:#5d93ff}.Pagination-module--pagination__prev-link--disable--Yklx9{pointer-events:none;color:#bbb}.Pagination-module--pagination__next--3hFiN{width:50%;text-align:right}.Pagination-module--pagination__next-link--3FUtA{color:#f7a046;font-size:1.625rem;font-weight:700}.Pagination-module--pagination__next-link--3FUtA:focus,.Pagination-module--pagination__next-link--3FUtA:hover{color:#5d93ff}.Pagination-module--pagination__next-link--disable--30UwZ{pointer-events:none;color:#bbb}.Author-module--author--2Yefr{border-top:1px solid #e6e6e6;max-width:40rem;padding-top:1.25rem;line-height:1.625rem;margin-top:1.625rem;margin-bottom:3.25rem}.Author-module--author__bio-twitter--n-O9n{display:block;text-decoration:underline}@media screen and (min-width:685px){.Author-module--author--2Yefr{margin-left:auto;margin-right:auto}}.Content-module--content--3p512{max-width:59.0625rem;padding:0 .9375rem;margin:0 auto}.Content-module--content__title--2BDW9{font-size:2rem;max-width:40rem;font-weight:600;text-align:center;line-height:2.68125rem;margin:1.625rem auto 0}.Content-module--content__body--2TrQ- figure{margin-bottom:1.625rem}.Content-module--content__body--2TrQ- figure blockquote{font-style:italic;text-align:center;margin-top:0;padding:1.625rem 0}.Content-module--content__body--2TrQ- figure blockquote p{max-width:40rem;font-size:1.6817rem;margin-top:0;margin-bottom:1.625rem;line-height:2.4375rem}.Content-module--content__body--2TrQ- a{text-decoration:underline}.Content-module--content__body--2TrQ- *{max-width:40rem;margin-left:auto;margin-right:auto}.Content-module--content__body--2TrQ- img{max-width:100%}@media screen and (min-width:960px){.Content-module--content--3p512{padding:0}.Content-module--content__title--2BDW9{font-size:3rem;line-height:3.65625rem;margin-top:3.65625rem;margin-bottom:2.4375rem}.Content-module--content__body--2TrQ-,.Content-module--content__body--2TrQ- p{font-size:1.125rem;line-height:1.82813rem;margin-bottom:1.82813rem}}.Meta-module--meta__date--29eD7{font-style:italic}.Tags-module--tags--1L_ct{margin-bottom:.8125rem}.Tags-module--tags__list--91FqN{list-style:none;margin:0 -.625rem;padding:0}.Tags-module--tags__list-item--1M30P{display:inline-block;margin:.625rem .3125rem}.Tags-module--tags__list-item-link--3SL_8{display:inline-block;height:2.1875rem;padding:0 1.5rem;line-height:2.1875rem;border:1px solid #e6e6e6;text-decoration:none;border-radius:1.25rem;color:#222}.Tags-module--tags__list-item-link--3SL_8:focus,.Tags-module--tags__list-item-link--3SL_8:hover{color:#5d93ff}.Post-module--post__comments--25y6I,.Post-module--post__footer--3WzWU{max-width:40rem;margin:0 auto;padding:0 .9375rem}.Post-module--post__home-button--16Kl0{display:block;max-width:5.625rem;height:2.1875rem;padding:0 1.5rem;line-height:2.1875rem;text-align:center;color:#222;border:1px solid #e6e6e6;border-radius:1.25rem;font-size:1rem;font-weight:400;margin-left:auto;margin-right:auto;margin-top:1.625rem}.Post-module--post__home-button--16Kl0:focus,.Post-module--post__home-button--16Kl0:hover{color:#5d93ff}@media screen and (min-width:960px){.Post-module--post__comments--25y6I,.Post-module--post__footer--3WzWU{padding:0}.Post-module--post__home-button--16Kl0{position:fixed;max-width:auto;margin:0;top:30px;left:30px}}</style><meta name="generator" content="Gatsby 2.32.13"/><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-73011038-4', 'auto', {});
      
      
      
      
      
      }</script><link rel="alternate" type="application/rss+xml" title="All Coding Tutorials" href="/rss.xml"/><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-73379983-2"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){window.dataLayer && window.dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-73379983-2', {"send_page_view":false});
      }
      </script><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link rel="icon" href="/favicon-32x32.png?v=150486806df16b88a62b4fa5c9af70c8" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#F7A046"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=150486806df16b88a62b4fa5c9af70c8"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=150486806df16b88a62b4fa5c9af70c8"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=150486806df16b88a62b4fa5c9af70c8"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=150486806df16b88a62b4fa5c9af70c8"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=150486806df16b88a62b4fa5c9af70c8"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=150486806df16b88a62b4fa5c9af70c8"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=150486806df16b88a62b4fa5c9af70c8"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=150486806df16b88a62b4fa5c9af70c8"/><title data-react-helmet="true">Realtime Face Anti-Spoofing Detection using Python and TensorFlow - All Coding Tutorials</title><meta data-react-helmet="true" name="description" content="We will be looking at how to build a realtime face anti spoofing detection tool using TensorFlow and Python"/><meta data-react-helmet="true" property="og:site_name" content="Realtime Face Anti-Spoofing Detection using Python and TensorFlow - All Coding Tutorials"/><meta data-react-helmet="true" property="og:image" content="https://lumen.netlify.com/prem.jpg"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:title" content="Realtime Face Anti-Spoofing Detection using Python and TensorFlow - All Coding Tutorials"/><meta data-react-helmet="true" name="twitter:description" content="We will be looking at how to build a realtime face anti spoofing detection tool using TensorFlow and Python"/><meta data-react-helmet="true" name="twitter:image" content="https://lumen.netlify.com/prem.jpg"/><link as="script" rel="preload" href="/webpack-runtime-b77c3bb44bd92355f479.js"/><link as="script" rel="preload" href="/framework-1e331b2e9d55ebef6dec.js"/><link as="script" rel="preload" href="/532a2f07-92db97c0addf07d5cb73.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-295178be86a3b3d75701.js"/><link as="script" rel="preload" href="/app-b20c5314ee6a701b7065.js"/><link as="script" rel="preload" href="/styles-407fe62976dc5310c43e.js"/><link as="script" rel="preload" href="/cd95ea5cbd2c605f26db819f07999610c9ff4310-47973f60638a9a10efdb.js"/><link as="script" rel="preload" href="/component---src-templates-post-template-js-381c1b847824134fa4bd.js"/><link as="fetch" rel="preload" href="/page-data/posts/realtime-face-antispoofing-detection-using-python/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/251939775.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2549761526.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/401334301.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="Layout-module--layout--3Pyz6"><div><a class="Post-module--post__home-button--16Kl0" href="/">All Articles</a><div><div class="Content-module--content--3p512"><h1 class="Content-module--content__title--2BDW9">Realtime Face Anti-Spoofing Detection using Python and TensorFlow</h1><div class="Content-module--content__body--2TrQ-"><p><img src="https://unsplash.com/photos/zbLW0FG8XU8/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8MjZ8fGFpfGVufDB8fHx8MTYzNDk0Nzk3NQ&#x26;force=true" alt="Photo by [Myke Simon](https://unsplash.com/@myke_simon?utm_source=medium&#x26;utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&#x26;utm_medium=referral)"></p>
<h2 id="what-is-machine-learning" style="position:relative;"><a href="#what-is-machine-learning" aria-label="what is machine learning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine Learning</a>?</h2>
<p>It is a technology branch that allows computer systems to learn from vast amounts of data, <strong>identify patterns</strong> within images and text, and make <strong>statistical decisions</strong> with minimal human intervention.</p>
<p>At its most basic, <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a> uses pre-programmed algorithms that receive and analyse input data to predict output values within an acceptable range.</p>
<p>As new data is fed to these algorithms in <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a>, they learn and optimise their operations to improve performance, developing <strong><em>intelligence</em></strong> over time.</p>
<blockquote>
<h1 id="key-research-in-natural-language-processing-conversational-ai-computer-vision-reinforcement-learning-and-ai-ethics-drive-the-growth-and-exposure-of-ai" style="position:relative;"><a href="#key-research-in-natural-language-processing-conversational-ai-computer-vision-reinforcement-learning-and-ai-ethics-drive-the-growth-and-exposure-of-ai" aria-label="key research in natural language processing conversational ai computer vision reinforcement learning and ai ethics drive the growth and exposure of ai permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><em>Key research in natural language processing, conversational AI, computer vision, reinforcement learning, and AI ethics drive the growth and exposure of AI</em></h1>
</blockquote>
<p><a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a> powers almost all the social media applications nowadays from YouTube, Google, Facebook, Instagram, Baidu, Twitter, etc.</p>
<p>Even voice assistants like Siri, Google Assistant, and Alexa are powered through <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a>, particularly in NLP and Speech Recognition.</p>
<p>The branch of <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a> is enormous, but it all started small, and understanding the fundamentals is equally essential to know what is happening behind the curtains truly.</p>
<h2 id="what-is-facial-recognition" style="position:relative;"><a href="#what-is-facial-recognition" aria-label="what is facial recognition permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is Facial Recognition?</h2>
<p><img src="https://cdn-images-1.medium.com/max/12730/0*rijfxt57bqpNjSwN" alt="Photo by [dogherine](https://unsplash.com/@dogherine?utm_source=medium&#x26;utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&#x26;utm_medium=referral)"><em>Photo by <a href="https://unsplash.com/@dogherine?utm_source=medium&#x26;utm_medium=referral" target="_blank" rel="nofollow noopener noreferrer">dogherine</a> on <a href="https://unsplash.com?utm_source=medium&#x26;utm_medium=referral" target="_blank" rel="nofollow noopener noreferrer">Unsplash</a></em></p>
<p>When <a href="https://wiseai.tech/what-is-liveness-detection-and-why-is-it-important/" target="_blank" rel="nofollow noopener noreferrer">Apple FaceID first came out</a>, videos and memes flooded the internet, finding ways to bypass the <strong>facial authentication system</strong>.</p>
<p>Some have come up with creative methods, such as unlocking the phone using the owner’s face while asleep or displaying a photo of the owner into the camera.</p>
<blockquote>
<h1 id="the-best-way-to-enhance-security-is-through-facial-recognition--its-going-to-be-the-standard-very-soon" style="position:relative;"><a href="#the-best-way-to-enhance-security-is-through-facial-recognition--its-going-to-be-the-standard-very-soon" aria-label="the best way to enhance security is through facial recognition  its going to be the standard very soon permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>“The best way to enhance security is through facial recognition — it’s going to be the standard very soon.”</h1>
</blockquote>
<p>The goal of <a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">face recognition</a> is to extract a sequence of data representing the same face from an incoming image using a collection of training photos stored in a database. The significant challenge is ensuring that <a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">face recognition</a> process occurs in <a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">real-time</a>, which is something that not all biometric <a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">face recognition</a> software vendors offer.</p>
<p>In a more technical definition, <a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">facial recognition</a> is a technique for identifying or validating a person’s identification based on their <a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">face</a>. It records, analyses, and compares patterns depending on the individual’s <a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">facial</a> <a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">features</a>.</p>
<p><img src="https://cdn-images-1.medium.com/max/7998/0*Ze-6q475qIVVzC5n" alt="Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&#x26;utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&#x26;utm_medium=referral)"><em>Photo by <a href="https://unsplash.com/@markuswinkler?utm_source=medium&#x26;utm_medium=referral" target="_blank" rel="nofollow noopener noreferrer">Markus Winkler</a> on <a href="https://unsplash.com?utm_source=medium&#x26;utm_medium=referral" target="_blank" rel="nofollow noopener noreferrer">Unsplash</a></em></p>
<p><a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">Face detection</a> is a critical stage in recognising and finding human faces in pictures and videos.</p>
<p><a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">Face capture</a> converts analogue information (a face) to a collection of digital data (or vectors) depending on the individual’s facial characteristics.</p>
<p><a href="https://www.electronicid.eu/en/blog/post/face-recognition/en" target="_blank" rel="nofollow noopener noreferrer">Face matching</a> determines if two faces belong to the same individual.</p>
<h2 id="using-machine-learning-for-facial-recognition" style="position:relative;"><a href="#using-machine-learning-for-facial-recognition" aria-label="using machine learning for facial recognition permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Using <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine Learning</a> for Facial Recognition</h2>
<p><img src="https://cdn-images-1.medium.com/max/15904/0*5cZs7tmaRFgF0F3H" alt="Photo by [Arseny Togulev](https://unsplash.com/@tetrakiss?utm_source=medium&#x26;utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&#x26;utm_medium=referral)"><em>Photo by <a href="https://unsplash.com/@tetrakiss?utm_source=medium&#x26;utm_medium=referral" target="_blank" rel="nofollow noopener noreferrer">Arseny Togulev</a> on <a href="https://unsplash.com?utm_source=medium&#x26;utm_medium=referral" target="_blank" rel="nofollow noopener noreferrer">Unsplash</a></em></p>
<p>The idea of using <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">machine learning</a> for facial recognition is entirely driven by the quality and quantity of data that the machine learning model is trained on.</p>
<p>At its core, facial recognition is based on mathematical AI and <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">machine learning algorithms</a> that evaluate face landmarks or facial features to match them to photos of persons in a pre-existing database.</p>
<p>In this article, we will look at how a simple real-time facial recognition tool is implemented.</p>
<p>The complete code can be found in the link below:
<a href="https://github.com/Prem95/face-liveness-detector" target="_blank" rel="nofollow noopener noreferrer"><strong>GitHub - Prem95/face-liveness-detector: Realtime Face Anti Spoofing with Face Detector based on</strong></a></p>
<h2 id="why-build-this" style="position:relative;"><a href="#why-build-this" aria-label="why build this permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why Build This?</h2>
<p>Face anti-spoofing systems has lately attracted increasing attention due to its important role in securing face recognition systems from fraudulent attacks. This project aims to provide a starting point in recognising real and fake faces based on a model that is trained with publicly available dataset</p>
<h2 id="where-to-use" style="position:relative;"><a href="#where-to-use" aria-label="where to use permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Where to use?</h2>
<p>This Face Anti Spoofing detector can be used in many different systems that needs realtime facial recognition with facial landmarks. Potentially could be used in security systems, biometrics, attendence systems and etc.</p>
<p>Can be integrated with hardware systems for application in offices, schools, and public places for various use cases.</p>
<h2 id="requirements" style="position:relative;"><a href="#requirements" aria-label="requirements permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Requirements</h2>
<p>For this project, we need OpenCV and Tensorflow so let’s install them.</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">$ pip install opencv-python
$ pip install tensorflow</code></pre></div>
<h2 id="installation" style="position:relative;"><a href="#installation" aria-label="installation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<p>Clone the repo</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">$ git clone [https://github.com/Prem95/face-liveness-detector.git](https://github.com/Prem95/face-liveness-detector.git)</code></pre></div>
<p>Change your directory to the cloned repo</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">$ cd face-liveness-detector</code></pre></div>
<p>Run the following command in your terminal</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">$ pip install -r requirements.txt</code></pre></div>
<h2 id="usage" style="position:relative;"><a href="#usage" aria-label="usage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h2>
<p>Run the following command in your terminal</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">$ python3 main.py</code></pre></div>
<h2 id="facial-recognition-model" style="position:relative;"><a href="#facial-recognition-model" aria-label="facial recognition model permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Facial Recognition Model</h2>
<p>The Facial Recognition model (<strong>anti-spoofing.h5</strong>) is trained using Tensorflow from publicly available datasets.</p>
<p>Below listed are the data sources that the model is trained on:</p>
<p><strong>CASIA</strong>: <a href="https://github.com/namtpham/casia2groundtruth" target="_blank" rel="nofollow noopener noreferrer">https://github.com/namtpham/casia2groundtruth</a></p>
<p><strong>OULU</strong>: <a href="https://sites.google.com/site/oulunpudatabase/" target="_blank" rel="nofollow noopener noreferrer">https://sites.google.com/site/oulunpudatabase/</a></p>
<p><strong>NUAA</strong>: <a href="http://parnec.nuaa.edu.cn/_upload/tpl/02/db/731/template731/pages/xtan/NUAAImposterDB_download.html" target="_blank" rel="nofollow noopener noreferrer">http://parnec.nuaa.edu.cn/<em>upload/tpl/02/db/731/template731/pages/xtan/NUAAImposterDB</em>download.html</a></p>
<p><strong>3DDFA</strong>: <a href="https://github.com/cleardusk/3DDFA" target="_blank" rel="nofollow noopener noreferrer">https://github.com/cleardusk/3DDFA</a> (Face Detector Library)</p>
<p><em>Please obtain the necessary permissions before using the datasets above</em></p>
<h2 id="face-detector" style="position:relative;"><a href="#face-detector" aria-label="face detector permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Face Detector</h2>
<p>The open-source library detects the facial landmarks and the number of faces present in the viewpoint. To check how is it implemented, you can check out the repo below:
<a href="https://github.com/cleardusk/3DDFA" target="_blank" rel="nofollow noopener noreferrer"><strong>GitHub - cleardusk/3DDFA: The PyTorch improved version of TPAMI 2017 paper: Face Alignment in Full…</strong></a></p>
<p>Using the face detector, we can obtain the facial landmarks of the faces that are detected.</p>
<h2 id="building-the-realtime-facial-recognition-tool" style="position:relative;"><a href="#building-the-realtime-facial-recognition-tool" aria-label="building the realtime facial recognition tool permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Building the Realtime Facial Recognition Tool</strong></h2>
<h3 id="face-detector-1" style="position:relative;"><a href="#face-detector-1" aria-label="face detector 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Face Detector</h3>
<p>The class below will return the face and facial landmarks such as eyes, nose, ears and mouth.</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">class FaceDetector(object):

    def __call__(self, img, dense_flag=False):

        faces = face_boxes(img)
        param_lst, roi_box_lst = tddfa(img, faces)
        landmarks = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)
        faces = np.array([[top, right, bottom, left] for left, top, right, bottom, _ in faces]).astype(int).tolist()
        return faces, landmarks</code></pre></div>
<h3 id="video-feed" style="position:relative;"><a href="#video-feed" aria-label="video feed permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Video Feed</h3>
<p>Using OpenCV, we can provide the webcam feed directly to the face detector to return the facial landmarks and number of faces present from the feed.</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text"># Read the video stream
video = cv2.VideoCapture(0)
while True:
    if not video.isOpened():
        print("[ERROR] Cannot find webcam")
        pass

    # Read the feed from webcam
    ret, frame = video.read()

    # Call face detector to obtain face image
    frame_bgr = frame[..., ::-1]
    boxes = face_detector(np.array(frame_bgr))</code></pre></div>
<h3 id="loading-the-trained-model" style="position:relative;"><a href="#loading-the-trained-model" aria-label="loading the trained model permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Loading the trained model</h3>
<p>The model is trained on publically available datasets using Keras with TensorFlow as the backend. Loading the model can quickly be done as below:</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">def load_keras_model(model_path):
    try:
        model = tf.keras.models.load_model(model_path, custom_objects={"lr": lambda x: x, "SparseCategoricalFocalLoss": lambda x: x})
        model.status = 0
    except Exception as e:
        class empty_model(object):
            def __init__(self):
                self.status = 600
        model = empty_model()
        print('[ERROR] Model failed to load. Check file path.')
        sys.exit()
    return model</code></pre></div>
<h3 id="calculating-the-face-score" style="position:relative;"><a href="#calculating-the-face-score" aria-label="calculating the face score permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Calculating the Face Score</h3>
<p>The trained model is used to detect if the faces that it sees are real or fake. By default, it has a threshold of 0.7, meaning that if the score is above 0.7, the model is confident that the face that appears on the video feed is a real face.</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">def load_keras_model(model_path):
    try:
        model = tf.keras.models.load_model(model_path, custom_objects={"lr": lambda x: x, "SparseCategoricalFocalLoss": lambda x: x})
        model.status = 0
    except Exception as e:
        class empty_model(object):
            def __init__(self):
                self.status = 600
        model = empty_model()
        print('[ERROR] Model failed to load. Check file path.')
        sys.exit()
    return model</code></pre></div>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*fPF8PYkSYRjt6umNh_5rkg.png" alt="Real Face Detection. Image source: Author (Please ignore my background)"><em>Real Face Detection. Image source: Author (Please ignore my background)</em></p>
<h3 id="displaying-the-face-and-face-score" style="position:relative;"><a href="#displaying-the-face-and-face-score" aria-label="displaying the face and face score permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Displaying the Face and Face Score</h3>
<p>Once we obtain the probability of the detected face, we can use OpenCV to add the bounding box directly on the face itself.</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text"># Check if face is present
n = len(boxes[0])
if n == 0:
    cv2.putText(frame, "Faces: %s" % (n), (500, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 200), 2)
else:
    cv2.putText(frame, "Faces: %s" % (n), (500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 200), 2)
    face_image = VideoUtils.get_liveness_score(frame, boxes[0])
    liveness_score = (np.round(model.predict(face_image)[:, 1].tolist()[0], 3))
    cv2.putText(frame, "Liveness: %s" % liveness_score, (20, 30), cv2.FONT_HERSHEY_DUPLEX,0.7, (0, 0, 200) if liveness_score &lt; 0.7 else (0, 200, 0), 1)
    cv2.rectangle(frame, (boxes[0][0][3], boxes[0][0][2]), (boxes[0][0][1], boxes[0][0][0]), (255, 0, 0), 2)

cv2.imshow("FAS Detector", frame)

# Reduce the frames for a more slower detection
key = cv2.waitKey(15)
if key == ord('q'):
    break</code></pre></div>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*ipXGIfTUpVFw20iBwPMMIg.png" alt="Fake Face Detection. Image source: Author (Please ignore my background)"><em>Fake Face Detection. Image source: Author (Please ignore my background)</em></p>
<h3 id="bonus-drawing-facial-landmark" style="position:relative;"><a href="#bonus-drawing-facial-landmark" aria-label="bonus drawing facial landmark permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Bonus: Drawing Facial Landmark</h3>
<p>Once the face landmark is obtained, we can overlap the face landmark points on the detected face.</p>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*1D6WJaPw-XxjTneYMXT7pg.png" alt="Face Landmarks. Image source: Author (Please ignore my background)"><em>Face Landmarks. Image source: Author (Please ignore my background)</em></p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">def draw_face_landmark(img_ori, pts, box=None, size=1):
  GREEN = (0, 255, 0)
  img = img_ori.copy()
  n = pts.shape[1]
  if n &lt;= 106:
      for i in range(n):
          cv2.circle(img, (int(round(pts[0, i])), int(round(pts[1, i]))), size, GREEN, -1)
  else:
      sep = 1
      for i in range(0, n, sep):
          cv2.circle(img, (int(round(pts[0, i])), int(round(pts[1, i]))), size, GREEN, 1)
  if box is not None:
      left, top, right, bottom = np.round(box).astype(np.int32)
      left_top = (left, top)
      right_top = (right, top)
      right_bottom = (right, bottom)
      left_bottom = (left, bottom)
      cv2.line(img, left_top, right_top, GREEN, 1, cv2.LINE_AA)
      cv2.line(img, right_top, right_bottom, GREEN, 1, cv2.LINE_AA)
      cv2.line(img, right_bottom, left_bottom, GREEN, 1, cv2.LINE_AA)
      cv2.line(img, left_bottom, left_top, GREEN, 1, cv2.LINE_AA)

  return img</code></pre></div>
<h2 id="in-recap" style="position:relative;"><a href="#in-recap" aria-label="in recap permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>In Recap</h2>
<p>Today, the amount of digital data generated is enormous thanks to smart devices and the Internet of Things.</p>
<p>This data can be analysed to make intelligent decisions based on patterns, and <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a> helps to do that while not being limited to the above applications.</p>
<p>Using <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a>, facial recognition related tasks can be improved by using state of the art research techniques to solve most problems nowadays related to security, etc.</p>
<p><a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a>-based models can extract patterns from massive amounts of data, which humans cannot do.</p>
<p>We cannot retain everything in memory or perform redundant computations for hours and days to develop exciting patterns. As per estimates, the Machine learning market will grow to reach <strong>USD 8.81 billion</strong> by 2022.</p>
<p>In the end, <a href="https://medium.com/geekculture/what-do-you-have-to-know-about-machine-learning-in-2021-d00b30aa5f11" target="_blank" rel="nofollow noopener noreferrer">Machine learning</a> is here to improve our lives beyond what we can imagine.</p>
<p>It is up to us to harness the power and make the right choices important to the people surrounding us and us.</p></div></div></div><div class="Post-module--post__footer--3WzWU"><div><p class="Meta-module--meta__date--29eD7">Published <!-- -->Oct 23, 2021</p></div><div class="Tags-module--tags--1L_ct"><ul class="Tags-module--tags__list--91FqN"><li class="Tags-module--tags__list-item--1M30P"><a class="Tags-module--tags__list-item-link--3SL_8" href="/tag/python/">Python</a></li><li class="Tags-module--tags__list-item--1M30P"><a class="Tags-module--tags__list-item-link--3SL_8" href="/tag/deep-learning/">Deep Learning</a></li><li class="Tags-module--tags__list-item--1M30P"><a class="Tags-module--tags__list-item-link--3SL_8" href="/tag/face-recognition/">Face Recognition</a></li><li class="Tags-module--tags__list-item--1M30P"><a class="Tags-module--tags__list-item-link--3SL_8" href="/tag/tensor-flow/">TensorFlow</a></li></ul></div><div class="Author-module--author--2Yefr"><p><a class="Author-module--author__bio-twitter--n-O9n" href="https://www.twitter.com/undefined" rel="noopener noreferrer" target="_blank"><strong>Prem Kumar</strong> on Twitter</a></p></div></div><div class="Post-module--post__comments--25y6I"></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/posts/realtime-face-antispoofing-detection-using-python";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-b11f7ed7be365f7aa0c9.js"],"app":["/app-b20c5314ee6a701b7065.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-fd4fb51a6fac1c18bdde.js"],"component---src-templates-categories-list-template-js":["/component---src-templates-categories-list-template-js-2181ec47d28e5c35d3e9.js"],"component---src-templates-category-template-js":["/component---src-templates-category-template-js-6a4ccb9f4a6261541e29.js"],"component---src-templates-index-template-js":["/component---src-templates-index-template-js-fdd8536acd3c57081720.js"],"component---src-templates-not-found-template-js":["/component---src-templates-not-found-template-js-658f4507169e2836a377.js"],"component---src-templates-page-template-js":["/component---src-templates-page-template-js-d8aeb4e67f2e8af3e6cd.js"],"component---src-templates-post-template-js":["/component---src-templates-post-template-js-381c1b847824134fa4bd.js"],"component---src-templates-tag-template-js":["/component---src-templates-tag-template-js-6f77d5f667fd901ff51f.js"],"component---src-templates-tags-list-template-js":["/component---src-templates-tags-list-template-js-2d7007993fc2bf0f9caf.js"]};/*]]>*/</script><script src="/polyfill-b11f7ed7be365f7aa0c9.js" nomodule=""></script><script src="/component---src-templates-post-template-js-381c1b847824134fa4bd.js" async=""></script><script src="/cd95ea5cbd2c605f26db819f07999610c9ff4310-47973f60638a9a10efdb.js" async=""></script><script src="/styles-407fe62976dc5310c43e.js" async=""></script><script src="/app-b20c5314ee6a701b7065.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-295178be86a3b3d75701.js" async=""></script><script src="/532a2f07-92db97c0addf07d5cb73.js" async=""></script><script src="/framework-1e331b2e9d55ebef6dec.js" async=""></script><script src="/webpack-runtime-b77c3bb44bd92355f479.js" async=""></script></body></html>